# vendedora.py (v26.2 - Reconhecimento de Prazo)
import json
import logging
import re
from openai import OpenAI, OpenAIError
from typing import Optional, List, Dict, Any

# --- Importa√ß√£o de Configura√ß√µes e Prompts ---
from sarah_bot.config import OPENAI_API_KEY, OPENAI_MODEL, OPENAI_ANALYSIS_MODEL
from sarah_bot.prompt_sarah import construir_prompt_sarah

# --- Configura√ß√£o do Cliente OpenAI ---
client = OpenAI(api_key=OPENAI_API_KEY)
logger = logging.getLogger(__name__)


# --- FUN√á√ïES DE EXTRA√á√ÉO DE DADOS ---

def extrair_quantidade_da_mensagem(mensagem: str) -> int:
    """Usa express√µes regulares para extrair de forma confi√°vel o primeiro n√∫mero encontrado."""
    numeros = re.findall(r'\d+', mensagem)
    if numeros:
        logger.info(f"Quantidade extra√≠da da mensagem via regex: {numeros[0]}")
        return int(numeros[0])
    logger.info("Nenhuma quantidade num√©rica encontrada na mensagem via regex.")
    return 0

def extrair_nome_da_mensagem(mensagem_usuario: str) -> Optional[str]:
    """Usa a IA para extrair apenas o nome pr√≥prio de uma frase."""
    prompt = f"""
    Analise a frase a seguir e extraia APENAS o nome pr√≥prio da pessoa.
    Frase: "{mensagem_usuario}"
    Retorne um objeto JSON com a chave "nome". Se nenhum nome for encontrado, retorne null.
    Exemplos:
    - Frase: "Meu nome √© Gabriel Fazenda Sol Nascente" -> {{"nome": "Gabriel"}}
    - Frase: "Pode me chamar de Ana Clara" -> {{"nome": "Ana Clara"}}
    - Frase: "Quanto custa o produto?" -> {{"nome": null}}
    """
    try:
        resposta = client.chat.completions.create(
            model=OPENAI_ANALYSIS_MODEL,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.0,
            response_format={"type": "json_object"}
        )
        resultado = json.loads(resposta.choices[0].message.content)
        nome = resultado.get("nome")
        if nome and isinstance(nome, str):
            logger.info(f"Nome extra√≠do da mensagem '{mensagem_usuario}': '{nome}'")
            return nome.strip().title()
        return None
    except (OpenAIError, json.JSONDecodeError) as e:
        logger.error(f"üö® Erro ao extrair nome com IA: {e}", exc_info=True)
        return None


# --- FUN√á√ÉO PRINCIPAL DE AN√ÅLISE ---

def analisar_mensagem_com_ia(mensagem_usuario: str, historico_conversa: list) -> dict:
    """Analisa a mensagem do usu√°rio para extrair inten√ß√µes, perfil, sentimento e entidades."""
    historico_resumido = json.dumps(historico_conversa[-5:], ensure_ascii=False)
    
    prompt_analise = f"""
    Analise a seguinte mensagem de um cliente e o hist√≥rico da conversa para um sistema de seguran√ßa no agroneg√≥cio (SAF).
    **Hist√≥rico Recente:** {historico_resumido}
    **Mensagem Atual do Cliente:** "{mensagem_usuario}"

    **Sua Tarefa:** Retorne um objeto JSON V√ÅLIDO com a estrutura abaixo. Preencha todos os campos.
    {{
        "perfil_detectado": "...",
        "sentimento_principal": "...",
        "tags_relevantes": ["..."],
        "entidades_extraidas": {{"nome_fazenda": "...", "localizacao": "..."}},
        "etapa_jornada": "..."
    }}
    
    **GUIA DE ETAPA DA JORNADA:**
    - "DESCOBERTA": O cliente est√° aprendendo, perguntando "como funciona?", "o que √©?".
    - "CONSIDERACAO": O cliente est√° comparando, perguntando "qual o valor?", "por que √© melhor que X?", "qual o prazo?".
    - "DECISAO": O cliente est√° pronto para agir, dizendo "quero comprar", "como pago?", "vamos fechar".

    **GUIA DE TAGS:** [SAUDACAO, PEDIDO_INFORMACOES_GERAIS, PEDIDO_ORCAMENTO, DOR_FURTO_PROPRIO, DOR_INSEGURANCA_REGIAO, OBJEC√ÉO_PRECO, OBJEC√ÉO_ADIAMENTO, INTENCAO_FECHAMENTO, PEDIDO_VIDEO, INFORMOU_QUANTIDADE, APENAS_CURIOSIDADE, CONCORRENTE_MENCIONADO, FORA_DE_ESCOPO, QUESTIONAMENTO_PRAZO_ENTREGA]

    **Exemplos de An√°lise (Use como guia principal):**
    - Mensagem: "como funciona?" -> {{"etapa_jornada": "DESCOBERTA", "tags_relevantes": ["PEDIDO_INFORMACOES_GERAIS"]}}
    - Mensagem: "qual o valor?" -> {{"etapa_jornada": "CONSIDERACAO", "tags_relevantes": ["PEDIDO_ORCAMENTO"]}}
    - Mensagem: "quanto custa para 2 pivos?" -> {{"etapa_jornada": "CONSIDERACAO", "tags_relevantes": ["PEDIDO_ORCAMENTO", "INFORMOU_QUANTIDADE"]}}
    - Mensagem: "quero comprar" -> {{"etapa_jornada": "DECISAO", "tags_relevantes": ["INTENCAO_FECHAMENTO"]}}
    - Mensagem: "qual o prazo de instala√ß√£o?" -> {{"etapa_jornada": "CONSIDERACAO", "tags_relevantes": ["QUESTIONAMENTO_PRAZO_ENTREGA"]}}
    """
    try:
        resposta = client.chat.completions.create(
            model=OPENAI_ANALYSIS_MODEL,
            messages=[{"role": "user", "content": prompt_analise}],
            temperature=0.0,
            response_format={"type": "json_object"}
        )
        analise = json.loads(resposta.choices[0].message.content)
        logger.info(f"An√°lise da IA bem-sucedida: {analise}")
        if isinstance(analise, dict) and "tags_relevantes" in analise:
            return analise
        else:
            return {}
    except (OpenAIError, json.JSONDecodeError) as e:
        logger.error(f"üö® Erro na an√°lise com IA: {e}", exc_info=True)
        return {}


# --- FUN√á√ÉO PRINCIPAL DE GERA√á√ÉO DE RESPOSTA ---

def gerar_resposta_sarah(pergunta: str, cliente_info: Dict[str, Any], estado_conversa: str, historico_conversa: List[Dict[str, str]], perfil_cliente="neutro", tags_detectadas=None, usar_gatilho_escassez=False):
    """Gera a resposta da Sarah usando o modelo de IA principal, com base em todo o contexto."""
    prompt = construir_prompt_sarah(pergunta, cliente_info, estado_conversa, historico_conversa, perfil_cliente, tags_detectadas, usar_gatilho_escassez)
    try:
        resposta = client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.75,
            max_tokens=450,
        )
        return resposta.choices[0].message.content.strip()
    except OpenAIError as e:
        logger.error(f"üö® Erro na API da OpenAI ao gerar resposta: {e}", exc_info=True)
        return f"Pe√ßo desculpas, {cliente_info.get('nome', 'cliente')}. Estou com uma instabilidade em meu sistema. Poderia, por gentileza, enviar sua mensagem novamente em alguns instantes? üôè"
    except Exception as e:
        logger.error(f"üö® Erro inesperado ao gerar resposta: {e}", exc_info=True)
        return "Ops, tive um problema t√©cnico aqui. Pode reformular sua pergunta, por favor?"


# --- NOVAS FUN√á√ïES COM IA ---

def gerar_resumo_para_gerente(historico_conversa: List[Dict[str, str]]) -> str:
    """Usa a IA para gerar um resumo conciso da conversa para um vendedor humano."""
    if not historico_conversa:
        return "Nenhum hist√≥rico de conversa dispon√≠vel."

    historico_formatado = "\n".join(
        [f"{'Cliente' if msg['role'] == 'user' else 'Sarah'}: {msg['content']}" for msg in historico_conversa]
    )
    
    prompt = f"""
    Analise o seguinte hist√≥rico de conversa entre a vendedora Sarah e um cliente.
    Sua tarefa √© criar um resumo de no m√°ximo 3 linhas para o gerente de vendas.
    O resumo deve ser direto, em portugu√™s, e focar em:
    1. A principal "dor" ou necessidade do cliente.
    2. O √∫ltimo ponto discutido ou a √∫ltima pergunta feita pelo cliente.
    3. O sentimento geral do cliente (ex: interessado, c√©tico, pronto para comprar).
    Hist√≥rico da Conversa:
    ---
    {historico_formatado}
    ---
    Gere apenas o texto do resumo.
    """
    try:
        resposta = client.chat.completions.create(
            model=OPENAI_ANALYSIS_MODEL,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            max_tokens=150,
        )
        resumo = resposta.choices[0].message.content.strip()
        logger.info(f"Resumo da IA para gerente gerado com sucesso.")
        return resumo
    except OpenAIError as e:
        logger.error(f"üö® Erro ao gerar resumo com IA: {e}")
        return "N√£o foi poss√≠vel gerar o resumo da conversa."

def gerar_follow_up_personalizado(cliente_info: dict) -> str:
    """Usa a IA para gerar uma mensagem de follow-up √∫nica e pessoal."""
    # (Esta fun√ß√£o n√£o foi alterada, mas √© mantida por completude)
    historico_conversa = cliente_info.get('historico_conversa', [])
    historico_formatado = "\n".join(
        [f"{'Cliente' if msg['role'] == 'user' else 'Sarah'}: {msg['content']}" for msg in historico_conversa[-10:]]
    )

    prompt = f"""
    Voc√™ √© Sarah, a vendedora. Crie uma mensagem de follow-up curta e pessoal para reengajar um cliente.
    **Contexto do Cliente:**
    - **Nome:** {cliente_info.get('nome')}
    - **Principal Dor Mencionada:** {cliente_info.get('dor_mencionada')}
    - **√öltimas mensagens:**
    {historico_formatado}
    **Regras:**
    1. Seja amig√°vel, use o nome do cliente.
    2. Mencione sutilmente a dor que ele compartilhou.
    3. Termine com uma pergunta aberta e de baixa press√£o.
    4. N√ÉO mencione "follow-up". Soe natural.
    Gere apenas o texto da mensagem.
    """
    try:
        resposta = client.chat.completions.create(
            model=OPENAI_MODEL,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=250,
        )
        mensagem = resposta.choices[0].message.content.strip()
        logger.info(f"Follow-up personalizado para {cliente_info.get('user_id')} gerado com sucesso.")
        return mensagem
    except OpenAIError as e:
        logger.error(f"üö® Erro ao gerar follow-up com IA: {e}")
        return f"Ol√°, {cliente_info.get('nome')}! Tudo bem? Passando para saber se conseguiu avaliar a proposta do sistema SAF. Ficou alguma d√∫vida? Estou √† disposi√ß√£o!"